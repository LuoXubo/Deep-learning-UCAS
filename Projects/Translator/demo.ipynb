{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@Description :   \n",
    "@Author      :   Xubo Luo \n",
    "@Time        :   2024/06/19 21:18:51\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from utils import subsequent_mask\n",
    "from setting import MAX_LENGTH, DEVICE\n",
    "import numpy as np\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = \"I am a student\"\n",
    "output = translate_large(input_sentence, 'en', 'zh')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import sacrebleu\n",
    "import random\n",
    "import time\n",
    "import jieba\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "def is_english_sentence(sentence):\n",
    "    # 使用正则表达式检查句子中是否包含英文字母\n",
    "    english_pattern = re.compile(r'[a-zA-Z]')\n",
    "    match = english_pattern.search(sentence)\n",
    "    # True 表示这是英文句子\n",
    "    if match: \n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "# 这个smooth防止句子长度小于4而出现报错\n",
    "smooth = SmoothingFunction().method1\n",
    "def compute_bleu4(tokenizer, random_integers, model, device):\n",
    "    \"\"\"\n",
    "    计算BLEU4\n",
    "    :param tokenizer: tokenizer\n",
    "    :param random_integers: 这个是随机选择的测试集数据的编号\n",
    "    :param model: 模型\n",
    "    :param device: 设备\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # m1,m2存放英文的原数据与模型输出数据\n",
    "    m1, m2 = [], []\n",
    "    # m3,m4存放英文的原数据与模型输出数据\n",
    "    m3, m4 = [], []\n",
    "    model.eval()\n",
    "    # 存放测试数据\n",
    "    da = []\n",
    "    # 将随机选择的测试集数据编号添加到da中\n",
    "    for i in random_integers:\n",
    "        da.append(tokenizer.test[i])\n",
    "    # 对da中的数据进行编码\n",
    "    labels, x, _ = tokenizer.encode_all(da)\n",
    "    with torch.no_grad():\n",
    "        # 预测\n",
    "        y = predict(x, model, tokenizer, device)\n",
    "    # 这个p用于记录y的索引\n",
    "    p = 0\n",
    "    # 用于保存有效的索引\n",
    "    itg = []\n",
    "    # 这里我限制输入数据全部有效，如果有无效的数据，直接放弃本次计算\n",
    "    if len(y) != 10:\n",
    "        return 0\n",
    "    for i in labels:\n",
    "        # 取出有效的索引\n",
    "        itg.append(random_integers[i])\n",
    "    # 将真实数据与预测数据分别放到m1,m2,m3,m4中\n",
    "    for i in itg:\n",
    "        if is_english_sentence(tokenizer.test[i][1]):\n",
    "            m1.append(tokenizer.test[i][1])\n",
    "            m2.append([y[p]])\n",
    "        else:\n",
    "            m3.append(list(jieba.cut(tokenizer.test[i][1])))\n",
    "            m4.append([list(jieba.cut(y[p]))])\n",
    "        p += 1\n",
    "    smooth = SmoothingFunction().method1\n",
    "    # 计算英文的bleu4\n",
    "    b1 = [sacrebleu.sentence_bleu(candidate, refs).score for candidate, refs in zip(m1, m2)]\n",
    "    # 计算中文的bleu4\n",
    "    for i in range(len(m4)):\n",
    "        b2 = sentence_bleu(m4[i], m3[i], weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smooth) * 100\n",
    "        b1.append(b2)\n",
    "#     print(b1)\n",
    "#     print(sum(b1)/len(b1))\n",
    "    return sum(b1)/len(b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# cacluate bleu score\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [['我', '是', '一个', '学生']]\n",
    "candidate = [\"我\", '是',  \"一个\", '学生']\n",
    "# candidate = ['I', 'am', 'a', 'student']\n",
    "\n",
    "score = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "print(score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
